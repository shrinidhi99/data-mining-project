{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit0769a96148364928a8ad5b322499ce22",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     user_id  tweets_count  followers_count  friends_count  has_name  \\\n",
       "0    3610511          3057             5470           2385         1   \n",
       "1    5656162          3128              506            381         1   \n",
       "2    5682702          3158              264             87         1   \n",
       "3    6067292          3098              640            622         1   \n",
       "4    6015122          2012               62             64         1   \n",
       "5    6140012          3203              138            179         1   \n",
       "6    6134312          1183              128            168         1   \n",
       "7    6684602          3102             1062           1770         1   \n",
       "8    7046912          3113            23368            958         1   \n",
       "9    7470952          3186              760            712         1   \n",
       "10   8072492          2754              477            218         1   \n",
       "11   8291932          3127             1390           1177         1   \n",
       "12   8858022          3103              314            338         1   \n",
       "13   8927532          1437               97            203         1   \n",
       "14   8933252          1716              289           1930         1   \n",
       "15   9351052           400               93             78         1   \n",
       "16   9564632          3066             2242            918         1   \n",
       "17   9939012          3146              689            891         1   \n",
       "18   9993142          2886              505            571         1   \n",
       "19  10492262           770               81            181         1   \n",
       "20  11176152          1436              128            371         1   \n",
       "21  13260592          3130              899            305         1   \n",
       "22  14057516          3087              375           1039         1   \n",
       "23  14112759           157               46            146         1   \n",
       "24  14492555           291               57            110         1   \n",
       "\n",
       "    has_image  has_address  has_bio  profile_has_url  present_in_list  \\\n",
       "0           1            1        1                1                1   \n",
       "1           1            1        1                1                1   \n",
       "2           1            1        1                1                1   \n",
       "3           1            0        1                1                1   \n",
       "4           1            1        1                1                0   \n",
       "5           1            1        1                0                1   \n",
       "6           1            1        1                0                1   \n",
       "7           1            0        1                0                1   \n",
       "8           1            1        1                1                1   \n",
       "9           1            1        1                0                1   \n",
       "10          1            1        1                1                1   \n",
       "11          1            1        1                1                1   \n",
       "12          1            1        1                0                1   \n",
       "13          1            1        1                1                1   \n",
       "14          1            0        1                0                1   \n",
       "15          1            1        1                1                1   \n",
       "16          1            1        1                1                1   \n",
       "17          1            1        1                1                1   \n",
       "18          1            1        1                0                1   \n",
       "19          1            1        1                0                1   \n",
       "20          1            1        1                0                1   \n",
       "21          1            1        1                1                1   \n",
       "22          1            0        1                0                1   \n",
       "23          1            1        1                1                0   \n",
       "24          1            1        1                1                0   \n",
       "\n",
       "    friends_to_followers_ratio  label  \n",
       "0                     0.436015      1  \n",
       "1                     0.752964      1  \n",
       "2                     0.329545      1  \n",
       "3                     0.971875      1  \n",
       "4                     1.032258      1  \n",
       "5                     1.297101      1  \n",
       "6                     1.312500      1  \n",
       "7                     1.666667      1  \n",
       "8                     0.040996      1  \n",
       "9                     0.936842      1  \n",
       "10                    0.457023      1  \n",
       "11                    0.846763      1  \n",
       "12                    1.076433      1  \n",
       "13                    2.092784      1  \n",
       "14                    6.678201      1  \n",
       "15                    0.838710      1  \n",
       "16                    0.409456      1  \n",
       "17                    1.293179      1  \n",
       "18                    1.130693      1  \n",
       "19                    2.234568      1  \n",
       "20                    2.898438      1  \n",
       "21                    0.339266      1  \n",
       "22                    2.770667      1  \n",
       "23                    3.173913      1  \n",
       "24                    1.929825      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>tweets_count</th>\n      <th>followers_count</th>\n      <th>friends_count</th>\n      <th>has_name</th>\n      <th>has_image</th>\n      <th>has_address</th>\n      <th>has_bio</th>\n      <th>profile_has_url</th>\n      <th>present_in_list</th>\n      <th>friends_to_followers_ratio</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3610511</td>\n      <td>3057</td>\n      <td>5470</td>\n      <td>2385</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.436015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5656162</td>\n      <td>3128</td>\n      <td>506</td>\n      <td>381</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.752964</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5682702</td>\n      <td>3158</td>\n      <td>264</td>\n      <td>87</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.329545</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6067292</td>\n      <td>3098</td>\n      <td>640</td>\n      <td>622</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.971875</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6015122</td>\n      <td>2012</td>\n      <td>62</td>\n      <td>64</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.032258</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6140012</td>\n      <td>3203</td>\n      <td>138</td>\n      <td>179</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.297101</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6134312</td>\n      <td>1183</td>\n      <td>128</td>\n      <td>168</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.312500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6684602</td>\n      <td>3102</td>\n      <td>1062</td>\n      <td>1770</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7046912</td>\n      <td>3113</td>\n      <td>23368</td>\n      <td>958</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.040996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7470952</td>\n      <td>3186</td>\n      <td>760</td>\n      <td>712</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.936842</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>8072492</td>\n      <td>2754</td>\n      <td>477</td>\n      <td>218</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.457023</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>8291932</td>\n      <td>3127</td>\n      <td>1390</td>\n      <td>1177</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.846763</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>8858022</td>\n      <td>3103</td>\n      <td>314</td>\n      <td>338</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.076433</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>8927532</td>\n      <td>1437</td>\n      <td>97</td>\n      <td>203</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.092784</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>8933252</td>\n      <td>1716</td>\n      <td>289</td>\n      <td>1930</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6.678201</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>9351052</td>\n      <td>400</td>\n      <td>93</td>\n      <td>78</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.838710</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>9564632</td>\n      <td>3066</td>\n      <td>2242</td>\n      <td>918</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.409456</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>9939012</td>\n      <td>3146</td>\n      <td>689</td>\n      <td>891</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.293179</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>9993142</td>\n      <td>2886</td>\n      <td>505</td>\n      <td>571</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.130693</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10492262</td>\n      <td>770</td>\n      <td>81</td>\n      <td>181</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.234568</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>11176152</td>\n      <td>1436</td>\n      <td>128</td>\n      <td>371</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.898438</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>13260592</td>\n      <td>3130</td>\n      <td>899</td>\n      <td>305</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.339266</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>14057516</td>\n      <td>3087</td>\n      <td>375</td>\n      <td>1039</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.770667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>14112759</td>\n      <td>157</td>\n      <td>46</td>\n      <td>146</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.173913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>14492555</td>\n      <td>291</td>\n      <td>57</td>\n      <td>110</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.929825</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "source": [
    "## Feature selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:11]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_real = X[:1950] \n",
    "y_real = y[:1950]\n",
    "\n",
    "X_fake = X[1950:]\n",
    "y_fake = y[1950:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_real, y_real, test_size=0.2)\n",
    "X_train_fake, X_test_fake, y_train_fake, y_test_fake = train_test_split(X_fake, y_fake, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "type(X_train_real)"
   ]
  },
  {
   "source": [
    "### Combine real and fake into train and test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [X_train_real, X_train_fake]\n",
    "X_train = pd.concat(frames)\n",
    "\n",
    "frames = [y_train_real, y_train_fake]\n",
    "y_train = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [X_test_real, X_test_fake]\n",
    "X_test = pd.concat(frames)\n",
    "\n",
    "frames = [y_test_real, y_test_fake]\n",
    "y_test = pd.concat(frames)"
   ]
  },
  {
   "source": [
    "## Applying classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc:  0.9802073515551367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)   \n",
    "clf.fit(X_train, y_train) \n",
    "y_pred = clf.predict(X_test) \n",
    "\n",
    "from sklearn import metrics   \n",
    "print(\"Acc: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "### 2. Decision Tree\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc:  0.9698397737983034\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[652,  19],\n",
       "       [ 13, 377]])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    " \n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics   \n",
    "print(\"Acc: \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "source": [
    "### 3. Adaboost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc:  0.9773798303487277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import datasets\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics   \n",
    "print(\"Acc: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "### 4. SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc:  0.9566446748350612\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics   \n",
    "print(\"Acc: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ]
}